{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'Anderson Carlos Ferreira da Silva'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "from operator import attrgetter\n",
    "from skmultiflow.core.utils.utils import *\n",
    "from skmultiflow.classification.base import BaseClassifier\n",
    "from skmultiflow.classification.trees.hoeffding_tree import HoeffdingTree\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FEATURES_M = ''\n",
    "FEATURES_SQRT = 'sqrt'\n",
    "FEATURES_SQRT_INV = 'sqrt_inv'\n",
    "FEATURES_PERCENT = 'percent'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADFHoeffdingTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- [Hoeffding Tree](https://github.com/scikit-multiflow/scikit-multiflow/blob/17327dc81b7d6e35d533795ae13493ad08118708/skmultiflow/classification/trees/hoeffding_tree.py)\n",
    "- [Adaptive Random Forest Hoeffding Tree](https://github.com/Waikato/moa/blob/f5cdc1051a7247bb61702131aec3e62b40aa82f8/moa/src/main/java/moa/classifiers/trees/ARFHoeffdingTree.java)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ARFHoeffdingTree(HoeffdingTree):\n",
    "            \n",
    "    class RandomLearningNode(HoeffdingTree.ActiveLearningNode):                    \n",
    "        \"\"\"Random learning node.\n",
    "        Parameters\n",
    "        ----------\n",
    "        initial_class_observations: dict (class_value, weight) or None\n",
    "            Initial class observations\n",
    "        \"\"\"\n",
    "        def __init__(self, initial_class_observations, nb_attributes):\n",
    "            super().__init__(initial_class_observations)\n",
    "            self.nb_attributes = nb_attributes;\n",
    "            self.list_attributes = None\n",
    "            \n",
    "        def learn_from_instance(self, X, y, weight, ht):\n",
    "            \"\"\"Update the node with the provided instance.\n",
    "            Parameters\n",
    "            ----------\n",
    "            X: numpy.ndarray of length equal to the number of features.\n",
    "                Instance attributes for updating the node.\n",
    "            y: int\n",
    "                Instance class.\n",
    "            weight: float\n",
    "                Instance weight.\n",
    "            ht: HoeffdingTree\n",
    "                Hoeffding Tree to update.\n",
    "            \"\"\"            \n",
    "            self._observed_class_distribution[y] += weight                            \n",
    "            if not self.list_attributes:\n",
    "                self.list_attributes = [None] * self.nb_attributes\n",
    "                for j in range(self.nb_attributes):    \n",
    "                    is_unique = False\n",
    "                    while is_unique == False:\n",
    "                        self.list_attributes[j] = randint(0, self.nb_attributes - 1)\n",
    "                        is_unique = True\n",
    "                        for i in range(j):\n",
    "                            if self.list_attributes[j] == self.list_attributes[i]:\n",
    "                                is_unique = False\n",
    "                                break\n",
    "            \n",
    "            for j in range(self.nb_attributes):\n",
    "                i = self.list_attributes[j]\n",
    "                obs = self._attribute_observers[i]\n",
    "                if obs is None:\n",
    "                    if i in ht.nominal_attributes:\n",
    "                        obs = NominalAttributeClassObserver()\n",
    "                    else:\n",
    "                        obs = GaussianNumericAttributeClassObserver()\n",
    "                    self._attribute_observers[i] = obs\n",
    "            obs.observe_attribute_class(X[i], int(y), weight)\n",
    "            \n",
    "    class LearningNodeNB(RandomLearningNode):\n",
    "\n",
    "        def __init__(self, initial_class_observations, nb_attributes):\n",
    "            super().__init__(initial_class_observations, nb_attributes)            \n",
    "            \n",
    "        def get_class_votes(self, X, ht):\n",
    "            \"\"\"Get the votes per class for a given instance.\n",
    "            Parameters\n",
    "            ----------\n",
    "            X: numpy.ndarray of length equal to the number of features.\n",
    "                Instance attributes.\n",
    "            ht: HoeffdingTree\n",
    "                Hoeffding Tree.\n",
    "            Returns\n",
    "            -------\n",
    "            dict (class_value, weight)\n",
    "                Class votes for the given instance.\n",
    "            \"\"\"\n",
    "            if self.get_weight_seen() >= ht.nb_threshold:\n",
    "                return do_naive_bayes_prediction(X, self._observed_class_distribution, self._attribute_observers)\n",
    "            else:\n",
    "                return super().get_class_votes(X, ht)\n",
    "\n",
    "    class LearningNodeNBAdaptive(LearningNodeNB):\n",
    "        \"\"\"Learning node that uses Adaptive Naive Bayes models.\n",
    "        Parameters\n",
    "        ----------\n",
    "        initial_class_observations: dict (class_value, weight) or None\n",
    "            Initial class observations\n",
    "        \"\"\"\n",
    "        def __init__(self, initial_class_observations, nb_attributes):\n",
    "            \"\"\"LearningNodeNBAdaptive class constructor. \"\"\"\n",
    "            super().__init__(initial_class_observations, nb_attributes)\n",
    "            self._mc_correct_weight = 0.0\n",
    "            self._nb_correct_weight = 0.0\n",
    "\n",
    "        def learn_from_instance(self, X, y, weight, ht):\n",
    "            \"\"\"Update the node with the provided instance.\n",
    "            Parameters\n",
    "            ----------\n",
    "            X: numpy.ndarray of length equal to the number of features.\n",
    "                Instance attributes for updating the node.\n",
    "            y: int\n",
    "                Instance class.\n",
    "            weight: float\n",
    "                The instance's weight.\n",
    "            ht: HoeffdingTree\n",
    "                The Hoeffding Tree to update.\n",
    "            \"\"\"\n",
    "            if self._observed_class_distribution == {}:\n",
    "                # All classes equal, default to class 0\n",
    "                if 0 == y:\n",
    "                    self._mc_correct_weight += weight\n",
    "            elif max(self._observed_class_distribution, key=self._observed_class_distribution.get) == y:\n",
    "                self._mc_correct_weight += weight\n",
    "            nb_prediction = do_naive_bayes_prediction(X, self._observed_class_distribution, self._attribute_observers)\n",
    "            if max(nb_prediction, key=nb_prediction.get) == y:\n",
    "                self._nb_correct_weight += weight\n",
    "            super().learn_from_instance(X, y, weight, ht)\n",
    "\n",
    "        def get_class_votes(self, X, ht):\n",
    "            \"\"\"Get the votes per class for a given instance.\n",
    "            Parameters\n",
    "            ----------\n",
    "            X: numpy.ndarray of length equal to the number of features.\n",
    "                Instance attributes.\n",
    "            ht: HoeffdingTree\n",
    "                Hoeffding Tree.\n",
    "            Returns\n",
    "            -------\n",
    "            dict (class_value, weight)\n",
    "                Class votes for the given instance.\n",
    "            \"\"\"\n",
    "            if self._mc_correct_weight > self._nb_correct_weight:\n",
    "                return self._observed_class_distribution\n",
    "            return do_naive_bayes_prediction(X, self._observed_class_distribution, self._attribute_observers)\n",
    "        \n",
    "    def __init__(self, max_byte_size = 33554432, memory_estimate_period = 1000000, grace_period = 200,\n",
    "                     split_criterion = 'info_gain', split_confidence = 0.0000001, tie_threshold = 0.05, \n",
    "                     binary_split = False, stop_mem_management = False, remove_poor_atts = False, no_preprune = False, \n",
    "                     leaf_prediction = 'mc', nb_threshold = 0, nominal_attributes = None, nb_attributes = 2):                \n",
    "        \"\"\"ADFHoeffdingTree class constructor.\"\"\"\n",
    "        super().__init__(max_byte_size, memory_estimate_period, grace_period, split_criterion, split_confidence,\n",
    "                        tie_threshold, binary_split, stop_mem_management, remove_poor_atts, no_preprune,\n",
    "                        leaf_prediction, nb_threshold, nominal_attributes)\n",
    "        self.nb_attributes = nb_attributes\n",
    "        self.remove_poor_attributes_option = None        \n",
    "\n",
    "    def newLearningNode(self, initial_class_observations):        \n",
    "        if self._leaf_prediction == MAJORITY_CLASS:\n",
    "            return RandomLearningNode(self, initialClassObservations, self.nb_attributes)            \n",
    "        elif self._leaf_prediction == NAIVE_BAYES:\n",
    "            return LearningNodeNB(self, initialClassObservations, self.nb_attributes)            \n",
    "        else: #NAIVE_BAYES_ADAPTIVE\n",
    "            return LearningNodeNBAdaptative(self, initialClassObservations, self.nb_attributes)\n",
    "            \n",
    "    def isRandomizable():\n",
    "        return True;\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Adaptive Random Forest](https://github.com/Waikato/moa/blob/master/moa/src/main/java/moa/classifiers/meta/AdaptiveRandomForest.java)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdaptiveRandomForest(BaseClassifier):\n",
    "    \n",
    "    def __init__(self, nb_ensemble = 10, feature_mode = 'sqrt', nb_features_per_tree = 2, \n",
    "                 disable_drift_detection = False, disable_background_learner = False):                \n",
    "        \"\"\".\"\"\"\n",
    "        super().__init__()          \n",
    "        self.nb_ensemble = nb_ensemble        \n",
    "        self.feature_mode = feature_mode\n",
    "        self.nb_features_per_tree = nb_features_per_tree\n",
    "        self.disable_drift_detection = disable_drift_detection\n",
    "        self.disable_background_Learner = disable_background_learner        \n",
    "        self.x_seen = 0        \n",
    "        self.ensemble = None     \n",
    "        self.nb_attributes = None        \n",
    "        #to fix\n",
    "        self.drift_detection_method = None\n",
    "        self.warning_detection_method = None        \n",
    "        \"\"\"\n",
    "        public ClassOption driftDetectionMethodOption = new ClassOption(\"driftDetectionMethod\", 'x',\n",
    "            \"Change detector for drifts and its parameters\", ChangeDetector.class, \"ADWINChangeDetector -a 1.0E-5\");\n",
    "\n",
    "        public ClassOption warningDetectionMethodOption = new ClassOption(\"warningDetectionMethod\", 'p',\n",
    "            \"Change detector for warnings (start training bkg learner)\", ChangeDetector.class, \"ADWINChangeDetector -a 1.0E-4\");\n",
    "   \n",
    "        \"\"\"\n",
    "    \n",
    "    def fit(self, X, y, classes=None, weight=None):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def partial_fit(self, X, y, classes=None, weight=None):\n",
    "        self.x_seen = self.x_seen + 1\n",
    "        \n",
    "        if not self.ensemble:\n",
    "            self.init()\n",
    "        \n",
    "        # to fix start\n",
    "        #Collection<TrainingRunnable> trainers = new ArrayList<TrainingRunnable>();\n",
    "        trainers = []\n",
    "        #for (int i = 0 ; i < this.ensemble.length ; i++) {\n",
    "        for i in range(self.nb_ensemble):\n",
    "        #    DoubleVector vote = new DoubleVector(this.ensemble[i].getVotesForInstance(instance));\n",
    "            \n",
    "        #    InstanceExample example = new InstanceExample(instance);\n",
    "            example = (X,y)\n",
    "        #    this.ensemble[i].evaluator.addResult(example, vote.getArrayRef());\n",
    "            \n",
    "        #    int k = MiscUtils.poisson(this.lambdaOption.getValue(), this.classifierRandom);\n",
    "            if k > 0:\n",
    "        #    if (k > 0) {\n",
    "                if self.executor:\n",
    "        #        if(this.executor != null) {\n",
    "                    trainer = TrainingRunnable(self.ensemble[i], X, y, k, self.instancesSeen)\n",
    "        #            TrainingRunnable trainer = new TrainingRunnable(this.ensemble[i], \n",
    "        #                instance, k, this.instancesSeen);\n",
    "                    trainers.append(trainer)\n",
    "        #            trainers.add(trainer);\n",
    "        #        }\n",
    "        #        else { // SINGLE_THREAD is in-place... \n",
    "                else:\n",
    "        #            this.ensemble[i].trainOnInstance(instance, k, this.instancesSeen);\n",
    "                    self.ensemble[i].partial_fit(X, y, k, self.instancesSeen)\n",
    "        #        }\n",
    "        #    }\n",
    "        #}\n",
    "        #if(this.executor != null) {\n",
    "        if self.executor:\n",
    "        #    try {\n",
    "        #        this.executor.invokeAll(trainers);\n",
    "            self.executor.invokeAll(trainers)\n",
    "        #    } catch (InterruptedException ex) {\n",
    "        #        throw new RuntimeException(\"Could not call invokeAll() on training threads.\");\n",
    "        #    }\n",
    "        #}\n",
    "        # to fix end\n",
    "    \n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def reset(self):        \n",
    "        \"\"\"Reset attributes.\"\"\"\n",
    "        self.ensemble = None;\n",
    "        self.nb_attributes = 0;\n",
    "        self.x_seen = 0;\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_info(self):\n",
    "        raise NotImplementedError   \n",
    "        \n",
    "    def init(X):\n",
    "        self.ensemble = [None] * self.nb_ensemble\n",
    "        \n",
    "        self.nb_attributes = self.nb_features_per_tree\n",
    "        \n",
    "        \"\"\"The size of m depends on:\"\"\"\n",
    "        _, n = get_dimensions(X)\n",
    "        \n",
    "        if self.feature_mode == FEATURES_SQRT:\n",
    "            self.nb_attributes = int(round(math.sqrt(n)) + 1)            \n",
    "        elif self.feature_mode == FEATURES_SQRT_INV:\n",
    "            self.nb_attributes = n - int(round(math.sqrt(n) + 1))\n",
    "        elif self.feature_mode == FEATURES_PERCENT:            \n",
    "            percent = (100 + self.nb_attributes) / 100.0 if self.nb_attributes < 0 else self.nb_attributes / 100.0\n",
    "            self.nb_attributes = int(round(n * percent))\n",
    "            \n",
    "        \"\"\"Notice that if the selected feature_mode was FEATURES_M then nothing is performed, \n",
    "        still it is necessary to check (and adjusted) for when a negative value was used. \n",
    "        \"\"\"\"\n",
    "        \n",
    "        \"\"\"\"m is negative, use size(features) + -m\"\"\"\"\n",
    "        if self.nb_attributes < 0:\n",
    "            self.nb_attributes = n + self.nb_attributes\n",
    "        \"\"\"\"Other sanity checks to avoid runtime errors.\"\"\"\"\n",
    "        \"\"\"\"m <= 0 (m can be negative if nb_attributes was negative and abs(m) > n), then use m = 1\"\"\"\"\n",
    "        if self.nb_attributes <= 0:\n",
    "            self.nb_attributes = 1\n",
    "        \"\"\"\"m > n, then it should use n\"\"\"\"\n",
    "        if self.nb_attributes > n:\n",
    "            self.nb_attributes = n;\n",
    "                               \n",
    "        for i in range(self.nb_ensemble):            \n",
    "            self.ensemble[i] = ARFBaseLearner(i, ARFHoeffdingTree(nb_attributes = self.nb_attributes), self.x_seen                                 \n",
    "                not self.disable_background_learner, not self.disable_drift_detection, self.drift_detection_method,\n",
    "                self.warning_detection_method, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
