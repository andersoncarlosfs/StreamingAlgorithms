{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'Anderson Carlos Ferreira da Silva'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import math\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from operator import attrgetter\n",
    "from skmultiflow.core.utils.utils import *\n",
    "from skmultiflow.core.base_object import BaseObject\n",
    "from skmultiflow.classification.base import BaseClassifier\n",
    "from skmultiflow.classification.trees.hoeffding_tree import *\n",
    "from skmultiflow.classification.core.driftdetection.adwin import ADWIN\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POISSON_SIZE = 1\n",
    "INSTANCE_WEIGHT = np.array([1.0])\n",
    "FEATURE_MODE_M = ''\n",
    "FEATURE_MODE_SQRT = 'sqrt'\n",
    "FEATURE_MODE_SQRT_INV = 'sqrt_inv'\n",
    "FEATURE_MODE_PERCENTAGE = 'percentage'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADFHoeffdingTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- [Hoeffding Tree](https://github.com/scikit-multiflow/scikit-multiflow/blob/17327dc81b7d6e35d533795ae13493ad08118708/skmultiflow/classification/trees/hoeffding_tree.py)\n",
    "- [Adaptive Random Forest Hoeffding Tree](https://github.com/Waikato/moa/blob/f5cdc1051a7247bb61702131aec3e62b40aa82f8/moa/src/main/java/moa/classifiers/trees/ARFHoeffdingTree.java)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attribute_observers(i, list_attributes, _attribute_observers, X, y, weight, ht):    \n",
    "    obs = _attribute_observers[i]\n",
    "    if obs is None:\n",
    "        if i in ht.nominal_attributes:\n",
    "            obs = NominalAttributeClassObserver()\n",
    "        else:\n",
    "            obs = GaussianNumericAttributeClassObserver()\n",
    "        _attribute_observers[i] = obs\n",
    "    obs.observe_attribute_class(X[i], int(y), weight)\n",
    "\n",
    "class ARFHoeffdingTree(HoeffdingTree):\n",
    "            \n",
    "    class RandomLearningNode(HoeffdingTree.ActiveLearningNode):                    \n",
    "        \"\"\"Random learning node.\n",
    "        Parameters\n",
    "        ----------\n",
    "        initial_class_observations: dict (class_value, weight) or None\n",
    "            Initial class observations\n",
    "        \"\"\"\n",
    "        def __init__(self, initial_class_observations, nb_attributes):\n",
    "            super().__init__(initial_class_observations)\n",
    "            self.nb_attributes = nb_attributes\n",
    "            self._attribute_observers = [None] * nb_attributes\n",
    "            self.list_attributes = []         \n",
    "            \n",
    "        def learn_from_instance(self, X, y, weight, ht):\n",
    "            \"\"\"Update the node with the provided instance.\n",
    "            Parameters\n",
    "            ----------\n",
    "            X: numpy.ndarray of length equal to the number of features.\n",
    "                Instance attributes for updating the node.\n",
    "            y: int\n",
    "                Instance class.\n",
    "            weight: float\n",
    "                Instance weight.\n",
    "            ht: HoeffdingTree\n",
    "                Hoeffding Tree to update.\n",
    "            \"\"\"   \n",
    "            if y not in self._observed_class_distribution:\n",
    "                self._observed_class_distribution[y] = 0.0            \n",
    "            \n",
    "            self._observed_class_distribution[y] += weight                            \n",
    "            if not self.list_attributes:\n",
    "                self.list_attributes = [None] * self.nb_attributes\n",
    "                for j in range(self.nb_attributes):    \n",
    "                    is_unique = False\n",
    "                    while is_unique == False:\n",
    "                        self.list_attributes[j] = randint(0, self.nb_attributes - 1)\n",
    "                        is_unique = True\n",
    "                        for i in range(j):\n",
    "                            if self.list_attributes[j] == self.list_attributes[i]:\n",
    "                                is_unique = False\n",
    "                                break\n",
    "            \n",
    "            Parallel(n_jobs = -1)(delayed(attribute_observers)(self.list_attributes[j], self._attribute_observers,\n",
    "                                                               X, y, weight, ht) for j in range(self.nb_attributes))\n",
    "            \"\"\"\n",
    "            for j in range(self.nb_attributes):\n",
    "                i = self.list_attributes[j]\n",
    "                obs = self._attribute_observers[i]\n",
    "                if obs is None:\n",
    "                    if i in ht.nominal_attributes:\n",
    "                        obs = NominalAttributeClassObserver()\n",
    "                    else:\n",
    "                        obs = GaussianNumericAttributeClassObserver()\n",
    "                    self._attribute_observers[i] = obs\n",
    "                obs.observe_attribute_class(X[i], int(y), weight)\n",
    "            \"\"\"\n",
    "            \n",
    "    class LearningNodeNB(RandomLearningNode):\n",
    "\n",
    "        def __init__(self, initial_class_observations, nb_attributes):\n",
    "            super().__init__(initial_class_observations, nb_attributes)            \n",
    "            \n",
    "        def get_class_votes(self, X, ht):\n",
    "            \"\"\"Get the votes per class for a given instance.\n",
    "            Parameters\n",
    "            ----------\n",
    "            X: numpy.ndarray of length equal to the number of features.\n",
    "                Instance attributes.\n",
    "            ht: HoeffdingTree\n",
    "                Hoeffding Tree.\n",
    "            Returns\n",
    "            -------\n",
    "            dict (class_value, weight)\n",
    "                Class votes for the given instance.\n",
    "            \"\"\"\n",
    "            if self.get_weight_seen() >= ht.nb_threshold:\n",
    "                return do_naive_bayes_prediction(X, self._observed_class_distribution, self._attribute_observers)\n",
    "            else:\n",
    "                return super().get_class_votes(X, ht)\n",
    "\n",
    "    class LearningNodeNBAdaptive(LearningNodeNB):\n",
    "        \"\"\"Learning node that uses Adaptive Naive Bayes models.\n",
    "        Parameters\n",
    "        ----------\n",
    "        initial_class_observations: dict (class_value, weight) or None\n",
    "            Initial class observations\n",
    "        \"\"\"\n",
    "        def __init__(self, initial_class_observations, nb_attributes):\n",
    "            \"\"\"LearningNodeNBAdaptive class constructor. \"\"\"\n",
    "            super().__init__(initial_class_observations, nb_attributes)\n",
    "            self._mc_correct_weight = 0.0\n",
    "            self._nb_correct_weight = 0.0\n",
    "\n",
    "        def learn_from_instance(self, X, y, weight, ht):\n",
    "            \"\"\"Update the node with the provided instance.\n",
    "            Parameters\n",
    "            ----------\n",
    "            X: numpy.ndarray of length equal to the number of features.\n",
    "                Instance attributes for updating the node.\n",
    "            y: int\n",
    "                Instance class.\n",
    "            weight: float\n",
    "                The instance's weight.\n",
    "            ht: HoeffdingTree\n",
    "                The Hoeffding Tree to update.\n",
    "            \"\"\"\n",
    "            if self._observed_class_distribution == {}:\n",
    "                # All classes equal, default to class 0\n",
    "                if 0 == y:\n",
    "                    self._mc_correct_weight += weight\n",
    "            elif max(self._observed_class_distribution, key=self._observed_class_distribution.get) == y:\n",
    "                self._mc_correct_weight += weight\n",
    "            nb_prediction = do_naive_bayes_prediction(X, self._observed_class_distribution, self._attribute_observers)\n",
    "            if max(nb_prediction, key=nb_prediction.get) == y:\n",
    "                self._nb_correct_weight += weight\n",
    "            super().learn_from_instance(X, y, weight, ht)\n",
    "\n",
    "        def get_class_votes(self, X, ht):\n",
    "            \"\"\"Get the votes per class for a given instance.\n",
    "            Parameters\n",
    "            ----------\n",
    "            X: numpy.ndarray of length equal to the number of features.\n",
    "                Instance attributes.\n",
    "            ht: HoeffdingTree\n",
    "                Hoeffding Tree.\n",
    "            Returns\n",
    "            -------\n",
    "            dict (class_value, weight)\n",
    "                Class votes for the given instance.\n",
    "            \"\"\"\n",
    "            if self._mc_correct_weight > self._nb_correct_weight:\n",
    "                return self._observed_class_distribution\n",
    "            return do_naive_bayes_prediction(X, self._observed_class_distribution, self._attribute_observers)\n",
    "        \n",
    "    def __init__(self, max_byte_size = 33554432, memory_estimate_period = 1000000, grace_period = 200,\n",
    "                     split_criterion = 'info_gain', split_confidence = 0.0000001, tie_threshold = 0.05, \n",
    "                     binary_split = False, stop_mem_management = False, remove_poor_atts = False, no_preprune = False, \n",
    "                     leaf_prediction = 'mc', nb_threshold = 0, nominal_attributes = None, nb_attributes = 2):                \n",
    "        \"\"\"ADFHoeffdingTree class constructor.\"\"\"\n",
    "        super().__init__(max_byte_size, memory_estimate_period, grace_period, split_criterion, split_confidence,\n",
    "                        tie_threshold, binary_split, stop_mem_management, remove_poor_atts, no_preprune,\n",
    "                        leaf_prediction, nb_threshold, nominal_attributes)\n",
    "        self.nb_attributes = nb_attributes\n",
    "        self.remove_poor_attributes_option = None        \n",
    "\n",
    "    def _new_learning_node(self, initial_class_observations = None):   \n",
    "        \"\"\"Create a new learning node. The type of learning node depends on the tree configuration.\"\"\"\n",
    "        if initial_class_observations is None:\n",
    "            initial_class_observations = {}        \n",
    "        if self._leaf_prediction == MAJORITY_CLASS:\n",
    "            return self.RandomLearningNode(initial_class_observations, self.nb_attributes)            \n",
    "        elif self._leaf_prediction == NAIVE_BAYES:\n",
    "            return self.LearningNodeNB(initial_class_observations, self.nb_attributes)            \n",
    "        else: #NAIVE_BAYES_ADAPTIVE\n",
    "            return self.LearningNodeNBAdaptative(initial_class_observations, self.nb_attributes)\n",
    "        \n",
    "    def is_randomizable():  \n",
    "        return True\n",
    "    \n",
    "    def copy(self):\n",
    "        return ARFHoeffdingTree(nb_attributes = self.nb_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Adaptive Random Forest](https://github.com/Waikato/moa/blob/master/moa/src/main/java/moa/classifiers/meta/AdaptiveRandomForest.java)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdaptiveRandomForest(BaseClassifier):\n",
    "    \n",
    "    def __init__(self, nb_ensemble = 10, feature_mode = 'sqrt', nb_attributes = 2, \n",
    "                 disable_background_learner = False, disable_drift_detection = False, \n",
    "                 disable_weighted_vote = False, w = 6, drift_detection_method = ADWIN, \n",
    "                 warning_detection_method = ADWIN):\n",
    "        \n",
    "        \"\"\"AdaptiveRandomForest class constructor.\"\"\"\n",
    "        super().__init__()          \n",
    "        self.nb_ensemble = nb_ensemble        \n",
    "        self.feature_mode = feature_mode\n",
    "        self.total_attributes = nb_attributes\n",
    "        self.disable_background_learner = disable_background_learner   \n",
    "        self.disable_drift_detection = disable_drift_detection        \n",
    "        self.disable_weighted_vote = disable_weighted_vote\n",
    "        self.w = w\n",
    "        self.drift_detection_method = drift_detection_method\n",
    "        self.warning_detection_method = warning_detection_method\n",
    "        self.X_seen = 0   \n",
    "        self._train_weight_seen_by_model = 0.0\n",
    "        self.nb_attributes = None\n",
    "        self.ensemble = None              \n",
    "\n",
    "    def fit(self, X, y, classes = None, weight = None):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def partial_fit(self, X, y, classes = None, weight = None):\n",
    "        if y is not None:\n",
    "            if weight is None:\n",
    "                weight = INSTANCE_WEIGHT\n",
    "            row_cnt, _ = get_dimensions(X)\n",
    "            wrow_cnt, _ = get_dimensions(weight)\n",
    "            if row_cnt != wrow_cnt:\n",
    "                weight = [weight[0]] * row_cnt\n",
    "            for i in range(row_cnt):\n",
    "                if weight[i] != 0.0:\n",
    "                    self._train_weight_seen_by_model += weight[i]\n",
    "                    self._partial_fit(X[i], y[i], weight[i])\n",
    "        \n",
    "    def _partial_fit(self, X, y, weight):\n",
    "        self.X_seen += 1\n",
    "        \n",
    "        if not self.ensemble:\n",
    "            self.init_ensemble(X)\n",
    "                      \n",
    "        for i in range(self.nb_ensemble):\n",
    "            vote = self.ensemble[i].get_votes_for_instance(X)\n",
    "            k = np.random.poisson(self.w, POISSON_SIZE)\n",
    "            if k > 0:\n",
    "                self.ensemble[i].partial_fit(np.asarray([X]), np.asarray([y]), np.asarray([k]), self.X_seen)            \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predicts the label of the X instance(s)\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: numpy.ndarray of shape (n_samples, n_features)\n",
    "            Samples for which we want to predict the labels.\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            Predicted labels for all instances in X.\n",
    "        \"\"\"\n",
    "        r, _ = get_dimensions(X)\n",
    "        predictions = []\n",
    "        for i in range(r):\n",
    "            votes = self.get_votes_for_instance(X[i])\n",
    "            if votes == {}:\n",
    "                # Tree is empty, all classes equal, default to zero\n",
    "                predictions.append(0)\n",
    "            else:\n",
    "                predict = []                \n",
    "                for vote in votes:                                        \n",
    "                    predict.append(max(vote, key = vote.get))            \n",
    "                y, counts = np.unique(predict, return_counts = True)\n",
    "                value = np.argmax(counts)                \n",
    "                predictions.append(y[value])                \n",
    "        return predictions\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def reset(self):        \n",
    "        \"\"\"Reset attributes.\"\"\"\n",
    "        self.ensemble = None\n",
    "        self.nb_attributes = 0\n",
    "        self.X_seen = 0\n",
    "        self._train_weight_seen_by_model = 0.0\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_info(self):\n",
    "        return \"NotImplementedError\"\n",
    "        \n",
    "    def get_votes_for_instance(self, X):\n",
    "        test = X.copy()\n",
    "        if not self.ensemble:\n",
    "            self.init_ensemble(test)\n",
    "        combined_vote = []\n",
    "           \n",
    "        for i in range(self.nb_ensemble):\n",
    "            vote = self.ensemble[i].get_votes_for_instance(test)\n",
    "            if sum(vote) > 0:\n",
    "                combined_vote.append(vote)\n",
    "        \n",
    "        return combined_vote\n",
    "        \n",
    "    def init_ensemble(self, X):\n",
    "        self.ensemble = [None] * self.nb_ensemble\n",
    "        \n",
    "        self.nb_attributes = self.total_attributes\n",
    "        \n",
    "        \"\"\"The m (total number of attributes) depends on:\"\"\"\n",
    "        _, n = get_dimensions(X)\n",
    "        \n",
    "        if self.feature_mode == FEATURE_MODE_SQRT:\n",
    "            self.nb_attributes = int(round(math.sqrt(n)) + 1)            \n",
    "        elif self.feature_mode == FEATURE_MODE_SQRT_INV:\n",
    "            self.nb_attributes = n - int(round(math.sqrt(n) + 1))\n",
    "        elif self.feature_mode == FEATURE_MODE_PERCENTAGE:            \n",
    "            percent = (100 + self.nb_attributes) / 100.0 if self.nb_attributes < 0 else self.nb_attributes / 100.0\n",
    "            self.nb_attributes = int(round(n * percent))\n",
    "            \n",
    "        \"\"\"Notice that if the selected feature_mode was FEATURE_MODE_M then nothing is performed, \n",
    "        still it is necessary to check (and adjusted) for when a negative value was used. \n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"m is negative, use size(features) + -m\"\"\"\n",
    "        if self.nb_attributes < 0:\n",
    "            self.nb_attributes += n\n",
    "        \"\"\"Other sanity checks to avoid runtime errors.\"\"\"\n",
    "        \"\"\"m <= 0 (m can be negative if nb_attributes was negative and abs(m) > n), then use m = 1\"\"\"\n",
    "        if self.nb_attributes <= 0:\n",
    "            self.nb_attributes = 1\n",
    "        \"\"\"m > n, then it should use n\"\"\"\n",
    "        if self.nb_attributes > n:\n",
    "            self.nb_attributes = n\n",
    "                               \n",
    "        for i in range(self.nb_ensemble):            \n",
    "            self.ensemble[i] = ARFBaseLearner(i, ARFHoeffdingTree(nb_attributes = self.nb_attributes), \n",
    "                                              self.X_seen, \n",
    "                                              not self.disable_background_learner, \n",
    "                                              not self.disable_drift_detection,\n",
    "                                              self.drift_detection_method,\n",
    "                                              self.warning_detection_method,\n",
    "                                              False)            \n",
    "                    \n",
    "    def is_randomizable():  \n",
    "        return True                \n",
    "            \n",
    "class ARFBaseLearner(BaseObject):\n",
    "\n",
    "    def __init__(self, index_original, classifier, X_seen, use_background_learner, use_drift_detector, \n",
    "                 drift_detection_method, warning_detection_method, is_background_learner):            \n",
    "        self.index_original = index_original\n",
    "        self.classifier = classifier \n",
    "        self.created_on = X_seen\n",
    "        self.use_background_learner = use_background_learner\n",
    "        self.use_drift_detector = use_drift_detector\n",
    "        self.is_background_learner = is_background_learner\n",
    "        self.drift_detection_method = warning_detection_method\n",
    "        self.warning_detection_method = warning_detection_method\n",
    "                                   \n",
    "        self.last_drift_on = 0\n",
    "        self.last_warning_on = 0\n",
    "        self.nb_drifts_detected = 0\n",
    "        self.nb_warnings_detected = 0            \n",
    "\n",
    "        self.drift_detection = None\n",
    "        self.warning_detection = None\n",
    "        self.background_learner = None\n",
    "\n",
    "        if use_background_learner:\n",
    "            self.warning_detection = warning_detection_method()\n",
    "            \n",
    "        if use_drift_detector:\n",
    "            self.drift_detection = drift_detection_method()\n",
    "            \n",
    "    def reset(self, X_seen):\n",
    "        if self.use_background_learner and self.background_learner:\n",
    "            self.classifier = self.background_learner.classifier \n",
    "            self.warning_detection = self.background_learner.warning_detection\n",
    "            self.drift_detection = self.background_learner.drift_detection\n",
    "            self.created_on = self.background_learner.created_on                \n",
    "            self.background_learner = None\n",
    "        else:\n",
    "            self.classifier.reset()\n",
    "            self.created_on = X_seen\n",
    "            self.drift_detection = self.drift_detection_method()            \n",
    "\n",
    "    def partial_fit(self, X, y, weight, X_seen):\n",
    "        X_weighted = X.copy()\n",
    "        self.classifier.partial_fit(X_weighted, y, weight)\n",
    "\n",
    "        if self.background_learner:\n",
    "            self.background_learner.classifier.partial_fit(X, y, INSTANCE_WEIGHT)\n",
    "\n",
    "        if self.use_drift_detector and not self.is_background_learner:\n",
    "            correctly_classifies = self.classifier.predict(X) == y\n",
    "            # Check for warning only if use_background_learner is active\n",
    "            if self.use_background_learner:\n",
    "                self.warning_detection.add_element(int(not correctly_classifies))\n",
    "                # Check if there was a change\n",
    "                if self.warning_detection.detected_change():\n",
    "                    self.last_warning_on = X_seen\n",
    "                    self.nb_warnings_detected += 1\n",
    "                    # Create a new background tree classifier\n",
    "                    background_learner = self.classifier.copy()\n",
    "                    background_learner.reset() \n",
    "                    # Create a new background learner object\n",
    "                    self.background_learner = ARFBaseLearner(self.index_original, background_learner, \n",
    "                                                             X_seen, self.use_background_learner, \n",
    "                                                             self.use_drift_detector, self.drift_detection_method, \n",
    "                                                             self.warning_detection_method, True)\n",
    "                    \"\"\"Update the warning detection object for the current object \n",
    "                    (this effectively resets changes made to the object while it was still a bkg learner). \n",
    "                    \"\"\"\n",
    "                    self.warning_detection = self.drift_detection_method()\n",
    "\n",
    "        # Update the drift detection\n",
    "        self.drift_detection.add_element(int(not correctly_classifies))\n",
    "\n",
    "        # Check if there was a change\n",
    "        if self.drift_detection.detected_change():\n",
    "            self.last_drift_on = X_seen\n",
    "            self.nb_drifts_detected += 1\n",
    "            self.reset(X_seen)\n",
    "\n",
    "    def get_votes_for_instance(self, X):\n",
    "        return self.classifier.get_votes_for_instance(X)\n",
    "\n",
    "    def get_class_type(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_info(self):\n",
    "        return \"NotImplementedError\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from skmultiflow.data.generators.waveform_generator import WaveformGenerator\n",
    "from skmultiflow.classification.trees.hoeffding_tree import HoeffdingTree\n",
    "from skmultiflow.evaluation.evaluate_prequential import EvaluatePrequential\n",
    "\n",
    "# 1. Create a stream\n",
    "stream = WaveformGenerator()\n",
    "stream.prepare_for_use()\n",
    "\n",
    "# 2. Instantiate the classifier\n",
    "adf = AdaptiveRandomForest()\n",
    "\n",
    "# 3. Setup the evaluator\n",
    "eval = EvaluatePrequential(show_plot = True, pretrain_size = 100, max_instances = 10000)\n",
    "\n",
    "# 4. Run evaluation\n",
    "eval.eval(stream = stream, classifier = adf)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
